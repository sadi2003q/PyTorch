{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GTPdHNM9o2AH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "zDal75jppUyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/fashion-mnist_train.csv')"
      ],
      "metadata": {
        "id": "WGfZ2XjSo5Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting and Scalling"
      ],
      "metadata": {
        "id": "ldmWYJpnpq49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_x = X_train/255.0\n",
        "test_x = X_test/255.0"
      ],
      "metadata": {
        "id": "bpcWiFDtpXcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for GPU Availability"
      ],
      "metadata": {
        "id": "wj4yToZWqJAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKiMaiprpdmu",
        "outputId": "899d247d-7763-4485-efd6-9155698c297c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Class and DataLoader"
      ],
      "metadata": {
        "id": "rFQ1H474rHx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = torch.tensor(x.values, dtype=torch.float32)\n",
        "    self.y = torch.tensor(y.values, dtype=torch.long)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.x[i], self.y[i]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "train_data = CustomDataSet(train_x, y_train)\n",
        "test_data = CustomDataSet(test_x, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "yTeH9RFpq5N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Model"
      ],
      "metadata": {
        "id": "h70VIfmKrmXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.BatchNorm1d(128), # Normalised the neurone\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Dropout(0.3), # Drop out some neurone\n",
        "        nn.Linear(128, 64),\n",
        "        nn.BatchNorm1d(64), # Normalised the neurone\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.output_layer = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.output_layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "G9atcgqdrktH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Parameter\n",
        "learning_rate = 0.01\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "6d9vTS8NsLxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising Model\n",
        "model = MyModel(train_x.shape[1]).to(device)\n",
        "\n",
        "# loss Function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4) # penalise the loss function"
      ],
      "metadata": {
        "id": "eEbc5lIgsRmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Pipeline"
      ],
      "metadata": {
        "id": "80a9FSSxsgWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    # Forward Pass\n",
        "    output = model(batch_features)\n",
        "    loss = loss_fn(output, batch_labels)\n",
        "\n",
        "    # Backward Pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update Gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {total_epoch_loss/len(train_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qG08StLsfOo",
        "outputId": "c88d0890-008c-44e2-95d3-6a08c9bf941a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.8788576284249624\n",
            "Epoch: 2, Loss: 0.5430560364524524\n",
            "Epoch: 3, Loss: 0.4787677427728971\n",
            "Epoch: 4, Loss: 0.443377348780632\n",
            "Epoch: 5, Loss: 0.4184263183871905\n",
            "Epoch: 6, Loss: 0.4045162236491839\n",
            "Epoch: 7, Loss: 0.38858470602830253\n",
            "Epoch: 8, Loss: 0.3768984512289365\n",
            "Epoch: 9, Loss: 0.3664283930460612\n",
            "Epoch: 10, Loss: 0.3570358684659004\n",
            "Epoch: 11, Loss: 0.3494120441973209\n",
            "Epoch: 12, Loss: 0.34409622504313786\n",
            "Epoch: 13, Loss: 0.335622811794281\n",
            "Epoch: 14, Loss: 0.3286780047218005\n",
            "Epoch: 15, Loss: 0.3237002332806587\n",
            "Epoch: 16, Loss: 0.3185934271613757\n",
            "Epoch: 17, Loss: 0.31147253163655597\n",
            "Epoch: 18, Loss: 0.3063351659576098\n",
            "Epoch: 19, Loss: 0.3026061212221781\n",
            "Epoch: 20, Loss: 0.29922945508360865\n",
            "Epoch: 21, Loss: 0.2942378022869428\n",
            "Epoch: 22, Loss: 0.28863375347852704\n",
            "Epoch: 23, Loss: 0.2859149602552255\n",
            "Epoch: 24, Loss: 0.28364309947689376\n",
            "Epoch: 25, Loss: 0.28030620063344636\n",
            "Epoch: 26, Loss: 0.27542208358645437\n",
            "Epoch: 27, Loss: 0.27095264651378\n",
            "Epoch: 28, Loss: 0.2687692493200302\n",
            "Epoch: 29, Loss: 0.2651306914190451\n",
            "Epoch: 30, Loss: 0.2616489218870799\n",
            "Epoch: 31, Loss: 0.26347074410319327\n",
            "Epoch: 32, Loss: 0.25654334930578865\n",
            "Epoch: 33, Loss: 0.2552118210196495\n",
            "Epoch: 34, Loss: 0.2502044911682606\n",
            "Epoch: 35, Loss: 0.24774665928383668\n",
            "Epoch: 36, Loss: 0.2478983983397484\n",
            "Epoch: 37, Loss: 0.24624590376019478\n",
            "Epoch: 38, Loss: 0.24132025987406572\n",
            "Epoch: 39, Loss: 0.23870723686615625\n",
            "Epoch: 40, Loss: 0.23813253848751387\n",
            "Epoch: 41, Loss: 0.2334674115628004\n",
            "Epoch: 42, Loss: 0.23447985542813937\n",
            "Epoch: 43, Loss: 0.23369849509000779\n",
            "Epoch: 44, Loss: 0.23016484501957893\n",
            "Epoch: 45, Loss: 0.22550776170690853\n",
            "Epoch: 46, Loss: 0.22259956051409244\n",
            "Epoch: 47, Loss: 0.22002866047124067\n",
            "Epoch: 48, Loss: 0.21768312221268812\n",
            "Epoch: 49, Loss: 0.22223577138284842\n",
            "Epoch: 50, Loss: 0.2174545295536518\n",
            "Epoch: 51, Loss: 0.21522851390143236\n",
            "Epoch: 52, Loss: 0.21851109262307486\n",
            "Epoch: 53, Loss: 0.21053811179598172\n",
            "Epoch: 54, Loss: 0.21005421485503514\n",
            "Epoch: 55, Loss: 0.20986542349557083\n",
            "Epoch: 56, Loss: 0.2090612155397733\n",
            "Epoch: 57, Loss: 0.20432517496744793\n",
            "Epoch: 58, Loss: 0.20405207034448783\n",
            "Epoch: 59, Loss: 0.20278572512666385\n",
            "Epoch: 60, Loss: 0.19915969388683638\n",
            "Epoch: 61, Loss: 0.2015902450978756\n",
            "Epoch: 62, Loss: 0.19867157578965028\n",
            "Epoch: 63, Loss: 0.19663637965420883\n",
            "Epoch: 64, Loss: 0.19395441390573978\n",
            "Epoch: 65, Loss: 0.1961633634865284\n",
            "Epoch: 66, Loss: 0.1949921508282423\n",
            "Epoch: 67, Loss: 0.19101581742366155\n",
            "Epoch: 68, Loss: 0.18838986928761006\n",
            "Epoch: 69, Loss: 0.18583396070698896\n",
            "Epoch: 70, Loss: 0.18718129453559718\n",
            "Epoch: 71, Loss: 0.18605173518757026\n",
            "Epoch: 72, Loss: 0.18532139725486438\n",
            "Epoch: 73, Loss: 0.18471631363530955\n",
            "Epoch: 74, Loss: 0.18380055724084376\n",
            "Epoch: 75, Loss: 0.18293348752955596\n",
            "Epoch: 76, Loss: 0.1824690013875564\n",
            "Epoch: 77, Loss: 0.17955164669950804\n",
            "Epoch: 78, Loss: 0.178470240359505\n",
            "Epoch: 79, Loss: 0.1758708833058675\n",
            "Epoch: 80, Loss: 0.1767664950489998\n",
            "Epoch: 81, Loss: 0.17133004536728064\n",
            "Epoch: 82, Loss: 0.1717614103257656\n",
            "Epoch: 83, Loss: 0.17306697531541188\n",
            "Epoch: 84, Loss: 0.1706407286922137\n",
            "Epoch: 85, Loss: 0.17085043942928313\n",
            "Epoch: 86, Loss: 0.1694561063547929\n",
            "Epoch: 87, Loss: 0.17056799990435442\n",
            "Epoch: 88, Loss: 0.16904572827120623\n",
            "Epoch: 89, Loss: 0.16615528366466364\n",
            "Epoch: 90, Loss: 0.16650879005591074\n",
            "Epoch: 91, Loss: 0.16916966810325781\n",
            "Epoch: 92, Loss: 0.1668590106666088\n",
            "Epoch: 93, Loss: 0.16021135779221854\n",
            "Epoch: 94, Loss: 0.1599275621920824\n",
            "Epoch: 95, Loss: 0.15986575357119243\n",
            "Epoch: 96, Loss: 0.15951758039494354\n",
            "Epoch: 97, Loss: 0.15894996244211992\n",
            "Epoch: 98, Loss: 0.15604693548878035\n",
            "Epoch: 99, Loss: 0.1603748195618391\n",
            "Epoch: 100, Loss: 0.1566572789400816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "OP73_1LttMXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "    total_samples += batch_labels.size(0)\n",
        "    total_correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5BAz2sWs-Td",
        "outputId": "891c2ddb-481b-4a5d-8fb0-6cf62142d1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8939166666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "    total_samples += batch_labels.size(0)\n",
        "    total_correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0HQMJM-tx7P",
        "outputId": "ed03740e-8921-44ac-975b-86010b552b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9703958333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zoUkK9CAt780"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}