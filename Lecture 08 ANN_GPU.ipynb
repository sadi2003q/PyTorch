{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GTPdHNM9o2AH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "zDal75jppUyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/fashion-mnist_train.csv')"
      ],
      "metadata": {
        "id": "WGfZ2XjSo5Np"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting and Scalling"
      ],
      "metadata": {
        "id": "ldmWYJpnpq49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop('label', axis=1)\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_x = X_train/255.0\n",
        "test_x = X_test/255.0"
      ],
      "metadata": {
        "id": "bpcWiFDtpXcJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check for GPU Availability"
      ],
      "metadata": {
        "id": "wj4yToZWqJAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKiMaiprpdmu",
        "outputId": "0a03aafb-5d14-4baa-9cf7-69c7df5310b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Class and DataLoader"
      ],
      "metadata": {
        "id": "rFQ1H474rHx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = torch.tensor(x.values, dtype=torch.float32)\n",
        "    self.y = torch.tensor(y.values, dtype=torch.long)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.x[i], self.y[i]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "train_data = CustomDataSet(train_x, y_train)\n",
        "test_data = CustomDataSet(test_x, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "yTeH9RFpq5N4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Model"
      ],
      "metadata": {
        "id": "h70VIfmKrmXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_features, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "G9atcgqdrktH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Parameter\n",
        "learning_rate = 0.1\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "6d9vTS8NsLxn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising Model\n",
        "model = MyModel(train_x.shape[1]).to(device)\n",
        "\n",
        "# loss Function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "eEbc5lIgsRmz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Pipeline"
      ],
      "metadata": {
        "id": "80a9FSSxsgWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  total_epoch_loss = 0\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features = batch_features.to(device)\n",
        "    batch_labels = batch_labels.to(device)\n",
        "\n",
        "    # Forward Pass\n",
        "    output = model(batch_features)\n",
        "    loss = loss_fn(output, batch_labels)\n",
        "\n",
        "    # Backward Pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update Gradient\n",
        "    optimizer.step()\n",
        "\n",
        "    total_epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch: {epoch+1}, Loss: {total_epoch_loss/len(train_loader)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qG08StLsfOo",
        "outputId": "0f8129a4-9c27-45b8-8d24-fbe29a4e12a6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.7393190166950225\n",
            "Epoch: 2, Loss: 0.4731459547877312\n",
            "Epoch: 3, Loss: 0.4175094682971636\n",
            "Epoch: 4, Loss: 0.3852225206295649\n",
            "Epoch: 5, Loss: 0.3607098419268926\n",
            "Epoch: 6, Loss: 0.34249720214804014\n",
            "Epoch: 7, Loss: 0.32889119786024096\n",
            "Epoch: 8, Loss: 0.31813872306545576\n",
            "Epoch: 9, Loss: 0.3053435844282309\n",
            "Epoch: 10, Loss: 0.2966456120312214\n",
            "Epoch: 11, Loss: 0.2848380032082399\n",
            "Epoch: 12, Loss: 0.27701505487660566\n",
            "Epoch: 13, Loss: 0.2684634185930093\n",
            "Epoch: 14, Loss: 0.26194801773130894\n",
            "Epoch: 15, Loss: 0.2551481956243515\n",
            "Epoch: 16, Loss: 0.24858039044837157\n",
            "Epoch: 17, Loss: 0.24080341357986132\n",
            "Epoch: 18, Loss: 0.23550920505325\n",
            "Epoch: 19, Loss: 0.230264292349418\n",
            "Epoch: 20, Loss: 0.22265910304586092\n",
            "Epoch: 21, Loss: 0.21982631140947342\n",
            "Epoch: 22, Loss: 0.21542733469605446\n",
            "Epoch: 23, Loss: 0.2086347139775753\n",
            "Epoch: 24, Loss: 0.20537772222856682\n",
            "Epoch: 25, Loss: 0.2007841658691565\n",
            "Epoch: 26, Loss: 0.19846336142718793\n",
            "Epoch: 27, Loss: 0.19381008500854174\n",
            "Epoch: 28, Loss: 0.18827655852834382\n",
            "Epoch: 29, Loss: 0.18419261063883702\n",
            "Epoch: 30, Loss: 0.18112843885024388\n",
            "Epoch: 31, Loss: 0.17827829945087434\n",
            "Epoch: 32, Loss: 0.17299501912295817\n",
            "Epoch: 33, Loss: 0.17197914802034697\n",
            "Epoch: 34, Loss: 0.17112619062761467\n",
            "Epoch: 35, Loss: 0.16452683951457342\n",
            "Epoch: 36, Loss: 0.16236782036721706\n",
            "Epoch: 37, Loss: 0.15916978837301335\n",
            "Epoch: 38, Loss: 0.15693443934619428\n",
            "Epoch: 39, Loss: 0.15236923966556787\n",
            "Epoch: 40, Loss: 0.15202213038504123\n",
            "Epoch: 41, Loss: 0.14801379319280386\n",
            "Epoch: 42, Loss: 0.1463407421335578\n",
            "Epoch: 43, Loss: 0.14155443761249384\n",
            "Epoch: 44, Loss: 0.13941792386521895\n",
            "Epoch: 45, Loss: 0.1353179426540931\n",
            "Epoch: 46, Loss: 0.13548782509565355\n",
            "Epoch: 47, Loss: 0.13341158874332903\n",
            "Epoch: 48, Loss: 0.13226286080976327\n",
            "Epoch: 49, Loss: 0.12760388246675333\n",
            "Epoch: 50, Loss: 0.12527260462691386\n",
            "Epoch: 51, Loss: 0.12239703472703695\n",
            "Epoch: 52, Loss: 0.12022175827249884\n",
            "Epoch: 53, Loss: 0.11946762180080016\n",
            "Epoch: 54, Loss: 0.11500843538468082\n",
            "Epoch: 55, Loss: 0.11558206974590818\n",
            "Epoch: 56, Loss: 0.11119244794547557\n",
            "Epoch: 57, Loss: 0.10860692763825258\n",
            "Epoch: 58, Loss: 0.10979265903805693\n",
            "Epoch: 59, Loss: 0.10701945513983567\n",
            "Epoch: 60, Loss: 0.10597564472506443\n",
            "Epoch: 61, Loss: 0.10323158218214909\n",
            "Epoch: 62, Loss: 0.10343465271281699\n",
            "Epoch: 63, Loss: 0.0992119700970749\n",
            "Epoch: 64, Loss: 0.0947963340866069\n",
            "Epoch: 65, Loss: 0.09646203070506454\n",
            "Epoch: 66, Loss: 0.09421315338214238\n",
            "Epoch: 67, Loss: 0.09537573962844909\n",
            "Epoch: 68, Loss: 0.09022249192744493\n",
            "Epoch: 69, Loss: 0.08951611535375317\n",
            "Epoch: 70, Loss: 0.08865646395770212\n",
            "Epoch: 71, Loss: 0.08453984841580192\n",
            "Epoch: 72, Loss: 0.08647665786805252\n",
            "Epoch: 73, Loss: 0.08658668387122452\n",
            "Epoch: 74, Loss: 0.0845630575803419\n",
            "Epoch: 75, Loss: 0.08061461404152215\n",
            "Epoch: 76, Loss: 0.08310925729200244\n",
            "Epoch: 77, Loss: 0.08390014789501826\n",
            "Epoch: 78, Loss: 0.074092863916109\n",
            "Epoch: 79, Loss: 0.07674924865489205\n",
            "Epoch: 80, Loss: 0.07522682517083983\n",
            "Epoch: 81, Loss: 0.07615450688016911\n",
            "Epoch: 82, Loss: 0.0736825581897671\n",
            "Epoch: 83, Loss: 0.07121017304869989\n",
            "Epoch: 84, Loss: 0.06884338688726227\n",
            "Epoch: 85, Loss: 0.06825605304415028\n",
            "Epoch: 86, Loss: 0.06829058461512129\n",
            "Epoch: 87, Loss: 0.06499573312948148\n",
            "Epoch: 88, Loss: 0.0681747904655834\n",
            "Epoch: 89, Loss: 0.0672079190928489\n",
            "Epoch: 90, Loss: 0.07092619820218533\n",
            "Epoch: 91, Loss: 0.06472211968588332\n",
            "Epoch: 92, Loss: 0.06226671769966682\n",
            "Epoch: 93, Loss: 0.06009588291496038\n",
            "Epoch: 94, Loss: 0.06236011678104599\n",
            "Epoch: 95, Loss: 0.058187874449261774\n",
            "Epoch: 96, Loss: 0.05470496338885277\n",
            "Epoch: 97, Loss: 0.05988773835698764\n",
            "Epoch: 98, Loss: 0.05459934390972679\n",
            "Epoch: 99, Loss: 0.05613792074968418\n",
            "Epoch: 100, Loss: 0.052921523162474234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "OP73_1LttMXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "    total_samples += batch_labels.size(0)\n",
        "    total_correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5BAz2sWs-Td",
        "outputId": "9a56c6d0-3b27-484d-fb3d-2021bde4ccfe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8874166666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    output = model(batch_features)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "\n",
        "    total_samples += batch_labels.size(0)\n",
        "    total_correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0HQMJM-tx7P",
        "outputId": "df9bb2b9-00e9-4be7-9c7f-a24a0eae3e3c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9750416666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zoUkK9CAt780"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}