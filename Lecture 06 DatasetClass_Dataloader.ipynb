{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "I1rppwJktU3s"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading"
      ],
      "metadata": {
        "id": "UNCDx-jbxMuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')"
      ],
      "metadata": {
        "id": "eoXcfbIZw2tM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting, Column removing and Encoding"
      ],
      "metadata": {
        "id": "--I0DQpKxPsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "X = df.drop(['diagnosis','Unnamed: 32'],axis=1)\n",
        "y = df['diagnosis']\n",
        "\n",
        "train_x, test_x, train_y, test_y = split(X,y,test_size=0.2, random_state = 42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "test_x = scaler.fit_transform(test_x)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "test_y = encoder.fit_transform(test_y)"
      ],
      "metadata": {
        "id": "D6EExSkJxI11"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting into Tensor"
      ],
      "metadata": {
        "id": "Z4ozNGMrgS6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "train_x = torch.from_numpy(train_x.astype(np.float32))\n",
        "train_y = torch.from_numpy(train_y.astype(np.float32))\n",
        "\n",
        "test_x = torch.from_numpy(test_x.astype(np.float32))\n",
        "test_y = torch.from_numpy(test_y.astype(np.float32))"
      ],
      "metadata": {
        "id": "zaWrL4-qgJMT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use of Custom Dataset and Dataloader"
      ],
      "metadata": {
        "id": "SSH9abYJgrbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "      return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      return self.features[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "-AdTC0NVglGL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_dataset = CustomDataset(train_x, train_y)\n",
        "test_x_dataset = CustomDataset(test_x, test_y)"
      ],
      "metadata": {
        "id": "GlfgHPvxhZlS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_dataloader = DataLoader(train_x_dataset, batch_size=4, shuffle=True)\n",
        "test_x_dataloader = DataLoader(test_x_dataset, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "J1J3DVqBhhOe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the model"
      ],
      "metadata": {
        "id": "4mqiwFH5i0wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super(MyModel, self).__init__()\n",
        "\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(num_features, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 8),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(8, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, features):\n",
        "    return self.network(features)\n"
      ],
      "metadata": {
        "id": "VW0twWJ7h-yP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Parameter"
      ],
      "metadata": {
        "id": "EWZjSzvZkqoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "epochs = 25"
      ],
      "metadata": {
        "id": "BLwejCbKkhn4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = MyModel(train_x.shape[1])\n",
        "\n",
        "# define Optimiser\n",
        "optimiser  = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# define loss function\n",
        "loss_fn = nn.BCELoss()"
      ],
      "metadata": {
        "id": "4WtwZeqbk_UR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Pipelie"
      ],
      "metadata": {
        "id": "ggbd16qvk0fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch_features, batch_labels in train_x_dataloader:\n",
        "\n",
        "    # foreword pass\n",
        "    y_pred = model(batch_features)\n",
        "\n",
        "    # loss calculation\n",
        "    loss = loss_fn(y_pred, batch_labels.view(-1, 1))\n",
        "\n",
        "    # clear Gradient\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # update the weights\n",
        "    optimiser.step()\n",
        "\n",
        "  # print output\n",
        "  print(f\"Epochs: {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgS_TW30ky-C",
        "outputId": "66d8095c-c746-4f3b-aa9a-fb3767a8443c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1, Loss: 0.004176496993750334\n",
            "Epochs: 2, Loss: 0.07810018211603165\n",
            "Epochs: 3, Loss: 0.012529191561043262\n",
            "Epochs: 4, Loss: 0.04047079756855965\n",
            "Epochs: 5, Loss: 1.66096031665802\n",
            "Epochs: 6, Loss: 3.964467396144755e-05\n",
            "Epochs: 7, Loss: 0.002223167335614562\n",
            "Epochs: 8, Loss: 0.00037291055195964873\n",
            "Epochs: 9, Loss: 0.02236497402191162\n",
            "Epochs: 10, Loss: 0.00840203370898962\n",
            "Epochs: 11, Loss: 0.0014376160688698292\n",
            "Epochs: 12, Loss: 0.00018280558288097382\n",
            "Epochs: 13, Loss: 0.0004011767159681767\n",
            "Epochs: 14, Loss: 3.4142280469495745e-07\n",
            "Epochs: 15, Loss: 0.007614761125296354\n",
            "Epochs: 16, Loss: 0.00030025787418708205\n",
            "Epochs: 17, Loss: 0.02665439434349537\n",
            "Epochs: 18, Loss: 3.1625947940483456e-06\n",
            "Epochs: 19, Loss: 0.00011792717123171315\n",
            "Epochs: 20, Loss: 0.0025922127533704042\n",
            "Epochs: 21, Loss: 0.0019700052216649055\n",
            "Epochs: 22, Loss: 0.011568107642233372\n",
            "Epochs: 23, Loss: 5.715872566924851e-11\n",
            "Epochs: 24, Loss: 1.4128873772278894e-05\n",
            "Epochs: 25, Loss: 1.9018048078578431e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "r1ShkVjmncmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation using test_loader\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "accuracy_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_features, batch_labels in test_x_dataloader:\n",
        "        # Forward pass\n",
        "        y_pred = model(batch_features)\n",
        "        y_pred = (y_pred > 0.8).float()  # Convert probabilities to binary predictions\n",
        "\n",
        "        # Calculate accuracy for the current batch\n",
        "        batch_accuracy = (y_pred.view(-1) == batch_labels).float().mean().item()\n",
        "        accuracy_list.append(batch_accuracy)\n",
        "\n",
        "# Calculate overall accuracy\n",
        "overall_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
        "print(f'Accuracy: {overall_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvXkR1rQmSsy",
        "outputId": "ba350918-23b8-4d40-f6f2-ea924d9338d6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyJyKPeBm6bE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}