{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QBxGbV-vz5vE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Dataset"
      ],
      "metadata": {
        "id": "qB4G9CY01mKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
        "           'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "\n",
        "df = pd.read_csv(url, names = columns)"
      ],
      "metadata": {
        "id": "pgzT168r1Sky"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace zero values with NaN in columns where zero is not a valid value\n",
        "cols_with_missing_vals = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "df[cols_with_missing_vals] = df[cols_with_missing_vals].replace(0, np.nan)\n",
        "\n",
        "# Impute the missing values with the mean of the respective column\n",
        "df.fillna(df.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "mctdv96I3b79"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Machine Learning Model\n",
        "\n"
      ],
      "metadata": {
        "id": "VwNanFUI2kJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "48j2ICp42YHh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(df.drop('Outcome', axis = 1), df['Outcome'], test_size = 0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_x_scalled = scaler.fit_transform(train_x)\n",
        "test_x_scalled = scaler.transform(test_x)"
      ],
      "metadata": {
        "id": "nIQZhCeZ3Euy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "Dc3IT0Rm4BIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logitic Regression\n",
        "model_logisticRegression = LogisticRegression()\n",
        "model_logisticRegression.fit(train_x_scalled, train_y)\n",
        "y_pred = q.predict(test_x_scalled)\n",
        "\n",
        "print(\"Accuracy (Logistic Regression): \", cross_val_score(model_logisticRegression, train_x_scalled, train_y, cv=5, scoring='accuracy').mean())\n",
        "\n",
        "# Random Forrest Classifier\n",
        "model_RandomForrest = RandomForestClassifier()\n",
        "model_RandomForrest.fit(train_x, train_y)\n",
        "y_pred = model_RandomForrest.predict(test_x_scalled)\n",
        "\n",
        "print(\"Accuracy (Random  Forrest): \", cross_val_score(model_RandomForrest, train_x_scalled, train_y, cv=5, scoring='accuracy').mean())\n",
        "\n",
        "# Desicion tree Classifier\n",
        "model_DecisionTree = DecisionTreeClassifier()\n",
        "model_DecisionTree.fit(train_x, train_y)\n",
        "y_pred = model_DecisionTree.predict(test_x_scalled)\n",
        "\n",
        "print(\"Accuracy (Decision Tree): \", cross_val_score(model_DecisionTree, train_x_scalled, train_y, cv=5, scoring='accuracy').mean())\n",
        "\n",
        "# Knearest Neighbour\n",
        "model_KNN = KNeighborsClassifier()\n",
        "model_KNN.fit(train_x, train_y)\n",
        "y_pred = model_KNN.predict(test_x_scalled)\n",
        "\n",
        "print(\"Accuracy (KNN): \", cross_val_score(model_KNN, train_x_scalled, train_y, cv=5, scoring='accuracy').mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jahMuODM35Mb",
        "outputId": "9c49d5b7-a1e7-4278-dc08-7faf8c16a11e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Logistic Regression):  0.7655071304811408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Random  Forrest):  0.7671331467413035\n",
            "Accuracy (Decision Tree):  0.6774756763961082\n",
            "Accuracy (KNN):  0.744368919099027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper Parameter Tunning using Optuna"
      ],
      "metadata": {
        "id": "iBfvXysh55kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "AtwVi1Ho5-UV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Objective Model\n",
        "def objective(trial):\n",
        "\n",
        "  # Suggest Value for parameter\n",
        "  n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
        "  max_depth = trial.suggest_int('max_depth', 1, 10)\n",
        "  min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
        "  max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
        "\n",
        "  # Create Random Forrest Classifier with Suggested Hyperparameter\n",
        "  model = RandomForestClassifier(\n",
        "      n_estimators=n_estimators,\n",
        "      max_depth=max_depth,\n",
        "      min_samples_split=min_samples_split,\n",
        "      min_samples_leaf=min_samples_leaf, max_features=max_features)\n",
        "\n",
        "  # Perform 10 Fold cross validation and calculate accuracy\n",
        "  accuracy = cross_val_score(model, train_x, train_y, cv=10, scoring='accuracy').mean()\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "BBLLW21O6KAT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create study object and optimise the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRH4E50d68vv",
        "outputId": "4cbbb505-5291-476c-e97a-299b91f6924e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-28 17:18:47,185] A new study created in memory with name: no-name-85af51e8-5f33-4bb7-b956-dc35d42ac85f\n",
            "[I 2025-01-28 17:18:54,988] Trial 0 finished with value: 0.7800634584875727 and parameters: {'n_estimators': 173, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:03,583] Trial 1 finished with value: 0.7718931782125859 and parameters: {'n_estimators': 237, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:08,276] Trial 2 finished with value: 0.765309360126917 and parameters: {'n_estimators': 170, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:14,670] Trial 3 finished with value: 0.7622686409307244 and parameters: {'n_estimators': 278, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:20,911] Trial 4 finished with value: 0.7783447911158118 and parameters: {'n_estimators': 260, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:26,247] Trial 5 finished with value: 0.7410629296668431 and parameters: {'n_estimators': 209, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:40,892] Trial 6 finished with value: 0.7604177683765203 and parameters: {'n_estimators': 469, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:48,095] Trial 7 finished with value: 0.7637228979375992 and parameters: {'n_estimators': 346, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:19:55,715] Trial 8 finished with value: 0.7493389740877843 and parameters: {'n_estimators': 390, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:03,125] Trial 9 finished with value: 0.7621099947117926 and parameters: {'n_estimators': 302, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:05,722] Trial 10 finished with value: 0.7573241671073506 and parameters: {'n_estimators': 100, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:13,264] Trial 11 finished with value: 0.7701745108408249 and parameters: {'n_estimators': 128, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:17,685] Trial 12 finished with value: 0.7735060814383923 and parameters: {'n_estimators': 192, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:23,586] Trial 13 finished with value: 0.7363035430988896 and parameters: {'n_estimators': 265, 'max_depth': 1, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:28,275] Trial 14 finished with value: 0.7734531993654151 and parameters: {'n_estimators': 156, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:34,579] Trial 15 finished with value: 0.7637757800105763 and parameters: {'n_estimators': 334, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:40,806] Trial 16 finished with value: 0.7556054997355897 and parameters: {'n_estimators': 225, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:53,810] Trial 17 finished with value: 0.762083553675304 and parameters: {'n_estimators': 433, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:20:58,126] Trial 18 finished with value: 0.7541248016922263 and parameters: {'n_estimators': 252, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:03,847] Trial 19 finished with value: 0.7490745637228979 and parameters: {'n_estimators': 331, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:10,621] Trial 20 finished with value: 0.7718402961396087 and parameters: {'n_estimators': 140, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:17,161] Trial 21 finished with value: 0.7735325224748809 and parameters: {'n_estimators': 190, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:24,221] Trial 22 finished with value: 0.7621364357482813 and parameters: {'n_estimators': 196, 'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:30,479] Trial 23 finished with value: 0.7800105764145954 and parameters: {'n_estimators': 166, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:36,405] Trial 24 finished with value: 0.7783712321523003 and parameters: {'n_estimators': 107, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:41,668] Trial 25 finished with value: 0.7702538339502908 and parameters: {'n_estimators': 107, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:46,594] Trial 26 finished with value: 0.7750925436277102 and parameters: {'n_estimators': 163, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:50,172] Trial 27 finished with value: 0.7734796404019038 and parameters: {'n_estimators': 129, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:54,087] Trial 28 finished with value: 0.7377578001057641 and parameters: {'n_estimators': 170, 'max_depth': 2, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:21:58,501] Trial 29 finished with value: 0.7653358011634056 and parameters: {'n_estimators': 227, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:00,773] Trial 30 finished with value: 0.7589635113696456 and parameters: {'n_estimators': 122, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:08,252] Trial 31 finished with value: 0.7783712321523003 and parameters: {'n_estimators': 244, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:12,111] Trial 32 finished with value: 0.7718402961396087 and parameters: {'n_estimators': 155, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:19,605] Trial 33 finished with value: 0.7767054468535166 and parameters: {'n_estimators': 291, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:27,305] Trial 34 finished with value: 0.770174510840825 and parameters: {'n_estimators': 242, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:31,506] Trial 35 finished with value: 0.7572184029613961 and parameters: {'n_estimators': 182, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:39,130] Trial 36 finished with value: 0.7750661025912216 and parameters: {'n_estimators': 219, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:44,799] Trial 37 finished with value: 0.7734531993654151 and parameters: {'n_estimators': 203, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:50,796] Trial 38 finished with value: 0.7589370703331572 and parameters: {'n_estimators': 152, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:54,455] Trial 39 finished with value: 0.7767318878900052 and parameters: {'n_estimators': 114, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:22:58,377] Trial 40 finished with value: 0.7750661025912216 and parameters: {'n_estimators': 136, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:23:08,480] Trial 41 finished with value: 0.7766261237440506 and parameters: {'n_estimators': 276, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:23:18,344] Trial 42 finished with value: 0.7670015864621893 and parameters: {'n_estimators': 311, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:23:31,784] Trial 43 finished with value: 0.7799576943416181 and parameters: {'n_estimators': 256, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:23:44,140] Trial 44 finished with value: 0.7735060814383924 and parameters: {'n_estimators': 249, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:24:05,049] Trial 45 finished with value: 0.7653886832363829 and parameters: {'n_estimators': 374, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:24:11,046] Trial 46 finished with value: 0.750793231094659 and parameters: {'n_estimators': 176, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:24:16,578] Trial 47 finished with value: 0.7685616076150185 and parameters: {'n_estimators': 214, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:24:18,922] Trial 48 finished with value: 0.7703595980962452 and parameters: {'n_estimators': 100, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:24:26,976] Trial 49 finished with value: 0.773532522474881 and parameters: {'n_estimators': 266, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:24:42,901] Trial 50 finished with value: 0.7442887361184558 and parameters: {'n_estimators': 477, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:24:53,456] Trial 51 finished with value: 0.7717609730301427 and parameters: {'n_estimators': 284, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:10,882] Trial 52 finished with value: 0.7717609730301428 and parameters: {'n_estimators': 304, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:16,936] Trial 53 finished with value: 0.773453199365415 and parameters: {'n_estimators': 238, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:26,710] Trial 54 finished with value: 0.7717874140666314 and parameters: {'n_estimators': 258, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:31,964] Trial 55 finished with value: 0.7669751454257006 and parameters: {'n_estimators': 205, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:37,144] Trial 56 finished with value: 0.7767318878900054 and parameters: {'n_estimators': 144, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:41,319] Trial 57 finished with value: 0.7621364357482813 and parameters: {'n_estimators': 228, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:47,811] Trial 58 finished with value: 0.7654944473823375 and parameters: {'n_estimators': 321, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:55,203] Trial 59 finished with value: 0.7750661025912214 and parameters: {'n_estimators': 275, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:25:59,800] Trial 60 finished with value: 0.7669487043892119 and parameters: {'n_estimators': 184, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:26:04,542] Trial 61 finished with value: 0.7620306716023268 and parameters: {'n_estimators': 142, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:26:07,827] Trial 62 finished with value: 0.7701745108408249 and parameters: {'n_estimators': 118, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:26:11,271] Trial 63 finished with value: 0.7685880486515071 and parameters: {'n_estimators': 149, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 0 with value: 0.7800634584875727.\n",
            "[I 2025-01-28 17:26:14,445] Trial 64 finished with value: 0.783262823902697 and parameters: {'n_estimators': 128, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:26:23,253] Trial 65 finished with value: 0.7734796404019038 and parameters: {'n_estimators': 168, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:26:26,401] Trial 66 finished with value: 0.7652829190904283 and parameters: {'n_estimators': 125, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:26:37,989] Trial 67 finished with value: 0.7816499206768905 and parameters: {'n_estimators': 445, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:26:46,359] Trial 68 finished with value: 0.7379428873611846 and parameters: {'n_estimators': 493, 'max_depth': 1, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:26:55,355] Trial 69 finished with value: 0.7507403490216816 and parameters: {'n_estimators': 415, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:27:06,142] Trial 70 finished with value: 0.7572712850343735 and parameters: {'n_estimators': 382, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:27:21,813] Trial 71 finished with value: 0.7767054468535166 and parameters: {'n_estimators': 349, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:27:35,504] Trial 72 finished with value: 0.7751189846641988 and parameters: {'n_estimators': 446, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:27:42,569] Trial 73 finished with value: 0.7734531993654151 and parameters: {'n_estimators': 160, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:27:50,711] Trial 74 finished with value: 0.7670015864621893 and parameters: {'n_estimators': 110, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:27:59,128] Trial 75 finished with value: 0.770174510840825 and parameters: {'n_estimators': 194, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:28:06,734] Trial 76 finished with value: 0.7767054468535166 and parameters: {'n_estimators': 134, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:28:18,736] Trial 77 finished with value: 0.7702009518773135 and parameters: {'n_estimators': 289, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:28:34,514] Trial 78 finished with value: 0.7702273929138023 and parameters: {'n_estimators': 244, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:28:46,025] Trial 79 finished with value: 0.7702009518773135 and parameters: {'n_estimators': 265, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:28:57,372] Trial 80 finished with value: 0.7588577472236911 and parameters: {'n_estimators': 361, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:02,207] Trial 81 finished with value: 0.7718402961396087 and parameters: {'n_estimators': 177, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:16,858] Trial 82 finished with value: 0.7767318878900052 and parameters: {'n_estimators': 402, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:21,269] Trial 83 finished with value: 0.766948704389212 and parameters: {'n_estimators': 124, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:23,867] Trial 84 finished with value: 0.7767318878900052 and parameters: {'n_estimators': 102, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:27,352] Trial 85 finished with value: 0.7800105764145954 and parameters: {'n_estimators': 151, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:35,296] Trial 86 finished with value: 0.7735325224748811 and parameters: {'n_estimators': 230, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:39,051] Trial 87 finished with value: 0.7491803278688524 and parameters: {'n_estimators': 160, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:43,377] Trial 88 finished with value: 0.7589370703331569 and parameters: {'n_estimators': 219, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:48,906] Trial 89 finished with value: 0.7554997355896351 and parameters: {'n_estimators': 133, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:29:58,353] Trial 90 finished with value: 0.7459016393442622 and parameters: {'n_estimators': 256, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:02,311] Trial 91 finished with value: 0.7783447911158117 and parameters: {'n_estimators': 147, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:07,299] Trial 92 finished with value: 0.778318350079323 and parameters: {'n_estimators': 149, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:10,058] Trial 93 finished with value: 0.7799841353781068 and parameters: {'n_estimators': 117, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:13,229] Trial 94 finished with value: 0.7799576943416182 and parameters: {'n_estimators': 114, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:17,644] Trial 95 finished with value: 0.776679005817028 and parameters: {'n_estimators': 117, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:22,028] Trial 96 finished with value: 0.7604706504494976 and parameters: {'n_estimators': 111, 'max_depth': 3, 'min_samples_split': 6, 'min_samples_leaf': 10, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:27,230] Trial 97 finished with value: 0.7636700158646219 and parameters: {'n_estimators': 137, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:30,302] Trial 98 finished with value: 0.7701745108408249 and parameters: {'n_estimators': 126, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n",
            "[I 2025-01-28 17:30:33,502] Trial 99 finished with value: 0.780037017451084 and parameters: {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 64 with value: 0.783262823902697.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best result\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)\n",
        "print('Best train Accuracy: ', study.best_trial.value)\n",
        "\n",
        "# print the parameter which is used to get the best values\n",
        "print(study.best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KdRw9kx7De_",
        "outputId": "9fcd657f-a231-4a9f-f5ad-d91915995faf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of finished trials: 100\n",
            "Best trial: {'n_estimators': 128, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': None}\n",
            "Best train Accuracy:  0.783262823902697\n",
            "{'n_estimators': 128, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 9, 'max_features': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training with best HyperParameter Found using Optuna"
      ],
      "metadata": {
        "id": "w3rvPUQF74wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train a random forrest classifier with best hyperparameter from optuna\n",
        "model = RandomForestClassifier(**study.best_trial.params)\n",
        "model.fit(train_x, train_y)\n",
        "y_pred = model.predict(test_x)\n",
        "print(f\"Accuracy: {accuracy_score(test_y, y_pred):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g3WVXWA789l",
        "outputId": "a4552c79-033d-4ddb-8664-2453a023fb35"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different Optimiser"
      ],
      "metadata": {
        "id": "3cCOzeX288fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default optimiser is TPE sampler\n",
        "study_2 = optuna.create_study(direction='maximize', sampler = optuna.samplers.RandomSampler())\n",
        "# another study sampler could be GridSampler\n",
        "study_2.optimize(objective, n_trials=20)"
      ],
      "metadata": {
        "id": "ltD3kktO8-w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualising Result"
      ],
      "metadata": {
        "id": "dxJgimxG9bId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U optuna plotly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnj1f1aM_C3w",
        "outputId": "d1985d86-2bd6-4d20-f25f-cc7c9fbdfc17"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_contour, plot_slice, plot_edf"
      ],
      "metadata": {
        "id": "ppr6TyeX9sy7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MNRuJgtR_Nsr",
        "outputId": "48e3f18a-2a6a-4033-994e-4f4a9aa91bef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4a3817f3-5cd0-4a42-9437-81cd83d3dec7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4a3817f3-5cd0-4a42-9437-81cd83d3dec7\")) {                    Plotly.newPlot(                        \"4a3817f3-5cd0-4a42-9437-81cd83d3dec7\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.7800634584875727,0.7718931782125859,0.765309360126917,0.7622686409307244,0.7783447911158118,0.7410629296668431,0.7604177683765203,0.7637228979375992,0.7493389740877843,0.7621099947117926,0.7573241671073506,0.7701745108408249,0.7735060814383923,0.7363035430988896,0.7734531993654151,0.7637757800105763,0.7556054997355897,0.762083553675304,0.7541248016922263,0.7490745637228979,0.7718402961396087,0.7735325224748809,0.7621364357482813,0.7800105764145954,0.7783712321523003,0.7702538339502908,0.7750925436277102,0.7734796404019038,0.7377578001057641,0.7653358011634056,0.7589635113696456,0.7783712321523003,0.7718402961396087,0.7767054468535166,0.770174510840825,0.7572184029613961,0.7750661025912216,0.7734531993654151,0.7589370703331572,0.7767318878900052,0.7750661025912216,0.7766261237440506,0.7670015864621893,0.7799576943416181,0.7735060814383924,0.7653886832363829,0.750793231094659,0.7685616076150185,0.7703595980962452,0.773532522474881,0.7442887361184558,0.7717609730301427,0.7717609730301428,0.773453199365415,0.7717874140666314,0.7669751454257006,0.7767318878900054,0.7621364357482813,0.7654944473823375,0.7750661025912214,0.7669487043892119,0.7620306716023268,0.7701745108408249,0.7685880486515071,0.783262823902697,0.7734796404019038,0.7652829190904283,0.7816499206768905,0.7379428873611846,0.7507403490216816,0.7572712850343735,0.7767054468535166,0.7751189846641988,0.7734531993654151,0.7670015864621893,0.770174510840825,0.7767054468535166,0.7702009518773135,0.7702273929138023,0.7702009518773135,0.7588577472236911,0.7718402961396087,0.7767318878900052,0.766948704389212,0.7767318878900052,0.7800105764145954,0.7735325224748811,0.7491803278688524,0.7589370703331569,0.7554997355896351,0.7459016393442622,0.7783447911158117,0.778318350079323,0.7799841353781068,0.7799576943416182,0.776679005817028,0.7604706504494976,0.7636700158646219,0.7701745108408249,0.780037017451084],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"y\":[0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.7800634584875727,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697,0.783262823902697],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4a3817f3-5cd0-4a42-9437-81cd83d3dec7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_param_importances(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "2GwtIZxT9-_P",
        "outputId": "87f5d695-8072-4bab-d379-b62c283ec5c7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"306fa562-c1eb-4510-8fcb-19fae962176f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"306fa562-c1eb-4510-8fcb-19fae962176f\")) {                    Plotly.newPlot(                        \"306fa562-c1eb-4510-8fcb-19fae962176f\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"min_samples_split (IntDistribution): 0.01072349995438587\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_estimators (IntDistribution): 0.011770197785904737\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"min_samples_leaf (IntDistribution): 0.027082722690690453\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"max_features (CategoricalDistribution): 0.09738805808916648\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"max_depth (IntDistribution): 0.8530355214798524\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.01\",\"0.01\",\"0.03\",\"0.10\",\"0.85\"],\"textposition\":\"outside\",\"x\":[0.01072349995438587,0.011770197785904737,0.027082722690690453,0.09738805808916648,0.8530355214798524],\"y\":[\"min_samples_split\",\"n_estimators\",\"min_samples_leaf\",\"max_features\",\"max_depth\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('306fa562-c1eb-4510-8fcb-19fae962176f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_contour(study)"
      ],
      "metadata": {
        "id": "WQmVqePM-BDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_slice(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "B_Yp2wy1-Cbf",
        "outputId": "2b541889-ba5b-4e25-ee9d-096de9dd5044"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a655ce2a-9628-4fea-9d0b-8d6bd2dfcf1b\" class=\"plotly-graph-div\" style=\"height:525px; width:1500px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a655ce2a-9628-4fea-9d0b-8d6bd2dfcf1b\")) {                    Plotly.newPlot(                        \"a655ce2a-9628-4fea-9d0b-8d6bd2dfcf1b\",                        [{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[4,10,6,6,5,2,10,10,2,4,8,4,4,1,7,5,3,8,5,3,7,4,3,5,5,7,6,5,2,8,4,5,6,5,6,3,5,4,6,7,5,6,4,5,5,4,3,5,6,4,2,5,5,6,4,9,5,3,7,4,6,5,5,4,5,5,6,4,1,3,4,5,4,5,4,6,5,4,6,5,3,5,5,4,5,4,4,3,4,6,2,5,5,4,4,4,3,4,4,4],\"y\":[0.7800634584875727,0.7718931782125859,0.765309360126917,0.7622686409307244,0.7783447911158118,0.7410629296668431,0.7604177683765203,0.7637228979375992,0.7493389740877843,0.7621099947117926,0.7573241671073506,0.7701745108408249,0.7735060814383923,0.7363035430988896,0.7734531993654151,0.7637757800105763,0.7556054997355897,0.762083553675304,0.7541248016922263,0.7490745637228979,0.7718402961396087,0.7735325224748809,0.7621364357482813,0.7800105764145954,0.7783712321523003,0.7702538339502908,0.7750925436277102,0.7734796404019038,0.7377578001057641,0.7653358011634056,0.7589635113696456,0.7783712321523003,0.7718402961396087,0.7767054468535166,0.770174510840825,0.7572184029613961,0.7750661025912216,0.7734531993654151,0.7589370703331572,0.7767318878900052,0.7750661025912216,0.7766261237440506,0.7670015864621893,0.7799576943416181,0.7735060814383924,0.7653886832363829,0.750793231094659,0.7685616076150185,0.7703595980962452,0.773532522474881,0.7442887361184558,0.7717609730301427,0.7717609730301428,0.773453199365415,0.7717874140666314,0.7669751454257006,0.7767318878900054,0.7621364357482813,0.7654944473823375,0.7750661025912214,0.7669487043892119,0.7620306716023268,0.7701745108408249,0.7685880486515071,0.783262823902697,0.7734796404019038,0.7652829190904283,0.7816499206768905,0.7379428873611846,0.7507403490216816,0.7572712850343735,0.7767054468535166,0.7751189846641988,0.7734531993654151,0.7670015864621893,0.770174510840825,0.7767054468535166,0.7702009518773135,0.7702273929138023,0.7702009518773135,0.7588577472236911,0.7718402961396087,0.7767318878900052,0.766948704389212,0.7767318878900052,0.7800105764145954,0.7735325224748811,0.7491803278688524,0.7589370703331569,0.7554997355896351,0.7459016393442622,0.7783447911158117,0.778318350079323,0.7799841353781068,0.7799576943416182,0.776679005817028,0.7604706504494976,0.7636700158646219,0.7701745108408249,0.780037017451084],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[null,\"log2\",null,\"sqrt\",null,null,null,\"log2\",\"sqrt\",null,\"sqrt\",null,null,null,null,\"log2\",null,null,\"sqrt\",\"log2\",null,null,null,null,null,null,null,null,\"sqrt\",\"log2\",\"log2\",null,null,null,null,null,null,null,\"sqrt\",null,null,null,null,null,null,null,\"sqrt\",null,\"log2\",null,null,null,null,null,null,null,null,\"sqrt\",\"log2\",null,null,null,null,null,null,null,null,null,null,\"log2\",\"sqrt\",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,\"sqrt\",\"log2\",null,null,null,null,null,null,null,null,null,null,null],\"y\":[0.7800634584875727,0.7718931782125859,0.765309360126917,0.7622686409307244,0.7783447911158118,0.7410629296668431,0.7604177683765203,0.7637228979375992,0.7493389740877843,0.7621099947117926,0.7573241671073506,0.7701745108408249,0.7735060814383923,0.7363035430988896,0.7734531993654151,0.7637757800105763,0.7556054997355897,0.762083553675304,0.7541248016922263,0.7490745637228979,0.7718402961396087,0.7735325224748809,0.7621364357482813,0.7800105764145954,0.7783712321523003,0.7702538339502908,0.7750925436277102,0.7734796404019038,0.7377578001057641,0.7653358011634056,0.7589635113696456,0.7783712321523003,0.7718402961396087,0.7767054468535166,0.770174510840825,0.7572184029613961,0.7750661025912216,0.7734531993654151,0.7589370703331572,0.7767318878900052,0.7750661025912216,0.7766261237440506,0.7670015864621893,0.7799576943416181,0.7735060814383924,0.7653886832363829,0.750793231094659,0.7685616076150185,0.7703595980962452,0.773532522474881,0.7442887361184558,0.7717609730301427,0.7717609730301428,0.773453199365415,0.7717874140666314,0.7669751454257006,0.7767318878900054,0.7621364357482813,0.7654944473823375,0.7750661025912214,0.7669487043892119,0.7620306716023268,0.7701745108408249,0.7685880486515071,0.783262823902697,0.7734796404019038,0.7652829190904283,0.7816499206768905,0.7379428873611846,0.7507403490216816,0.7572712850343735,0.7767054468535166,0.7751189846641988,0.7734531993654151,0.7670015864621893,0.770174510840825,0.7767054468535166,0.7702009518773135,0.7702273929138023,0.7702009518773135,0.7588577472236911,0.7718402961396087,0.7767318878900052,0.766948704389212,0.7767318878900052,0.7800105764145954,0.7735325224748811,0.7491803278688524,0.7589370703331569,0.7554997355896351,0.7459016393442622,0.7783447911158117,0.778318350079323,0.7799841353781068,0.7799576943416182,0.776679005817028,0.7604706504494976,0.7636700158646219,0.7701745108408249,0.780037017451084],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[10,2,8,7,8,1,4,3,6,1,10,10,8,9,5,8,10,6,9,7,9,8,7,9,9,10,9,9,10,7,4,9,9,10,8,9,8,7,2,10,6,8,9,10,10,10,9,10,9,10,5,8,9,8,9,10,8,7,9,10,9,8,8,7,9,10,9,10,10,10,9,9,10,9,10,10,9,9,3,10,8,8,8,9,6,9,10,9,9,1,5,8,9,7,7,7,10,4,7,6],\"y\":[0.7800634584875727,0.7718931782125859,0.765309360126917,0.7622686409307244,0.7783447911158118,0.7410629296668431,0.7604177683765203,0.7637228979375992,0.7493389740877843,0.7621099947117926,0.7573241671073506,0.7701745108408249,0.7735060814383923,0.7363035430988896,0.7734531993654151,0.7637757800105763,0.7556054997355897,0.762083553675304,0.7541248016922263,0.7490745637228979,0.7718402961396087,0.7735325224748809,0.7621364357482813,0.7800105764145954,0.7783712321523003,0.7702538339502908,0.7750925436277102,0.7734796404019038,0.7377578001057641,0.7653358011634056,0.7589635113696456,0.7783712321523003,0.7718402961396087,0.7767054468535166,0.770174510840825,0.7572184029613961,0.7750661025912216,0.7734531993654151,0.7589370703331572,0.7767318878900052,0.7750661025912216,0.7766261237440506,0.7670015864621893,0.7799576943416181,0.7735060814383924,0.7653886832363829,0.750793231094659,0.7685616076150185,0.7703595980962452,0.773532522474881,0.7442887361184558,0.7717609730301427,0.7717609730301428,0.773453199365415,0.7717874140666314,0.7669751454257006,0.7767318878900054,0.7621364357482813,0.7654944473823375,0.7750661025912214,0.7669487043892119,0.7620306716023268,0.7701745108408249,0.7685880486515071,0.783262823902697,0.7734796404019038,0.7652829190904283,0.7816499206768905,0.7379428873611846,0.7507403490216816,0.7572712850343735,0.7767054468535166,0.7751189846641988,0.7734531993654151,0.7670015864621893,0.770174510840825,0.7767054468535166,0.7702009518773135,0.7702273929138023,0.7702009518773135,0.7588577472236911,0.7718402961396087,0.7767318878900052,0.766948704389212,0.7767318878900052,0.7800105764145954,0.7735325224748811,0.7491803278688524,0.7589370703331569,0.7554997355896351,0.7459016393442622,0.7783447911158117,0.778318350079323,0.7799841353781068,0.7799576943416182,0.776679005817028,0.7604706504494976,0.7636700158646219,0.7701745108408249,0.780037017451084],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[4,9,10,3,7,8,5,5,5,4,2,7,7,6,3,7,6,4,8,2,4,7,8,6,6,5,6,3,4,9,6,6,5,6,10,6,9,8,5,3,5,7,7,7,6,8,6,7,4,5,7,7,8,6,7,6,8,5,2,7,4,8,9,8,9,9,6,10,10,10,10,9,10,5,6,3,9,7,10,6,4,8,9,8,7,8,6,5,7,9,7,8,8,6,6,6,6,6,5,6],\"y\":[0.7800634584875727,0.7718931782125859,0.765309360126917,0.7622686409307244,0.7783447911158118,0.7410629296668431,0.7604177683765203,0.7637228979375992,0.7493389740877843,0.7621099947117926,0.7573241671073506,0.7701745108408249,0.7735060814383923,0.7363035430988896,0.7734531993654151,0.7637757800105763,0.7556054997355897,0.762083553675304,0.7541248016922263,0.7490745637228979,0.7718402961396087,0.7735325224748809,0.7621364357482813,0.7800105764145954,0.7783712321523003,0.7702538339502908,0.7750925436277102,0.7734796404019038,0.7377578001057641,0.7653358011634056,0.7589635113696456,0.7783712321523003,0.7718402961396087,0.7767054468535166,0.770174510840825,0.7572184029613961,0.7750661025912216,0.7734531993654151,0.7589370703331572,0.7767318878900052,0.7750661025912216,0.7766261237440506,0.7670015864621893,0.7799576943416181,0.7735060814383924,0.7653886832363829,0.750793231094659,0.7685616076150185,0.7703595980962452,0.773532522474881,0.7442887361184558,0.7717609730301427,0.7717609730301428,0.773453199365415,0.7717874140666314,0.7669751454257006,0.7767318878900054,0.7621364357482813,0.7654944473823375,0.7750661025912214,0.7669487043892119,0.7620306716023268,0.7701745108408249,0.7685880486515071,0.783262823902697,0.7734796404019038,0.7652829190904283,0.7816499206768905,0.7379428873611846,0.7507403490216816,0.7572712850343735,0.7767054468535166,0.7751189846641988,0.7734531993654151,0.7670015864621893,0.770174510840825,0.7767054468535166,0.7702009518773135,0.7702273929138023,0.7702009518773135,0.7588577472236911,0.7718402961396087,0.7767318878900052,0.766948704389212,0.7767318878900052,0.7800105764145954,0.7735325224748811,0.7491803278688524,0.7589370703331569,0.7554997355896351,0.7459016393442622,0.7783447911158117,0.778318350079323,0.7799841353781068,0.7799576943416182,0.776679005817028,0.7604706504494976,0.7636700158646219,0.7701745108408249,0.780037017451084],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"colorbar\":{\"title\":{\"text\":\"Trial\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"name\":\"Feasible Trial\",\"showlegend\":false,\"x\":[173,237,170,278,260,209,469,346,390,302,100,128,192,265,156,334,225,433,252,331,140,190,196,166,107,107,163,129,170,227,122,244,155,291,242,182,219,203,152,114,136,276,311,256,249,374,176,214,100,266,477,284,304,238,258,205,144,228,321,275,184,142,118,149,128,168,125,445,493,415,382,349,446,160,110,194,134,289,244,265,361,177,402,124,102,151,230,160,219,133,256,147,149,117,114,117,111,137,126,100],\"y\":[0.7800634584875727,0.7718931782125859,0.765309360126917,0.7622686409307244,0.7783447911158118,0.7410629296668431,0.7604177683765203,0.7637228979375992,0.7493389740877843,0.7621099947117926,0.7573241671073506,0.7701745108408249,0.7735060814383923,0.7363035430988896,0.7734531993654151,0.7637757800105763,0.7556054997355897,0.762083553675304,0.7541248016922263,0.7490745637228979,0.7718402961396087,0.7735325224748809,0.7621364357482813,0.7800105764145954,0.7783712321523003,0.7702538339502908,0.7750925436277102,0.7734796404019038,0.7377578001057641,0.7653358011634056,0.7589635113696456,0.7783712321523003,0.7718402961396087,0.7767054468535166,0.770174510840825,0.7572184029613961,0.7750661025912216,0.7734531993654151,0.7589370703331572,0.7767318878900052,0.7750661025912216,0.7766261237440506,0.7670015864621893,0.7799576943416181,0.7735060814383924,0.7653886832363829,0.750793231094659,0.7685616076150185,0.7703595980962452,0.773532522474881,0.7442887361184558,0.7717609730301427,0.7717609730301428,0.773453199365415,0.7717874140666314,0.7669751454257006,0.7767318878900054,0.7621364357482813,0.7654944473823375,0.7750661025912214,0.7669487043892119,0.7620306716023268,0.7701745108408249,0.7685880486515071,0.783262823902697,0.7734796404019038,0.7652829190904283,0.7816499206768905,0.7379428873611846,0.7507403490216816,0.7572712850343735,0.7767054468535166,0.7751189846641988,0.7734531993654151,0.7670015864621893,0.770174510840825,0.7767054468535166,0.7702009518773135,0.7702273929138023,0.7702009518773135,0.7588577472236911,0.7718402961396087,0.7767318878900052,0.766948704389212,0.7767318878900052,0.7800105764145954,0.7735325224748811,0.7491803278688524,0.7589370703331569,0.7554997355896351,0.7459016393442622,0.7783447911158117,0.778318350079323,0.7799841353781068,0.7799576943416182,0.776679005817028,0.7604706504494976,0.7636700158646219,0.7701745108408249,0.780037017451084],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.16799999999999998],\"title\":{\"text\":\"max_depth\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.208,0.376],\"title\":{\"text\":\"max_features\"},\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"sqrt\",\"log2\",null]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.416,0.584],\"title\":{\"text\":\"min_samples_leaf\"}},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.624,0.792],\"title\":{\"text\":\"min_samples_split\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.832,1.0],\"title\":{\"text\":\"n_estimators\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"Slice Plot\"},\"width\":1500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a655ce2a-9628-4fea-9d0b-8d6bd2dfcf1b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_edf(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ojDh4HV2-Dks",
        "outputId": "bd87b605-e6ff-489d-96f5-3f74b24aab39"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"141fe1a4-aeb1-493c-b033-db3a1287d04e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"141fe1a4-aeb1-493c-b033-db3a1287d04e\")) {                    Plotly.newPlot(                        \"141fe1a4-aeb1-493c-b033-db3a1287d04e\",                        [{\"mode\":\"lines\",\"name\":\"no-name-85af51e8-5f33-4bb7-b956-dc35d42ac85f\",\"x\":[0.7363035430988896,0.736777879268625,0.7372522154383604,0.7377265516080959,0.7382008877778313,0.7386752239475667,0.7391495601173022,0.7396238962870376,0.740098232456773,0.7405725686265084,0.7410469047962438,0.7415212409659793,0.7419955771357147,0.7424699133054501,0.7429442494751856,0.743418585644921,0.7438929218146564,0.7443672579843919,0.7448415941541273,0.7453159303238627,0.7457902664935981,0.7462646026633336,0.746738938833069,0.7472132750028044,0.7476876111725399,0.7481619473422753,0.7486362835120107,0.7491106196817461,0.7495849558514815,0.750059292021217,0.7505336281909524,0.7510079643606878,0.7514823005304233,0.7519566367001587,0.7524309728698941,0.7529053090396296,0.753379645209365,0.7538539813791004,0.7543283175488359,0.7548026537185712,0.7552769898883067,0.7557513260580422,0.7562256622277775,0.756699998397513,0.7571743345672484,0.7576486707369838,0.7581230069067193,0.7585973430764547,0.7590716792461901,0.7595460154159256,0.760020351585661,0.7604946877553964,0.7609690239251319,0.7614433600948672,0.7619176962646027,0.7623920324343382,0.7628663686040735,0.763340704773809,0.7638150409435445,0.7642893771132798,0.7647637132830153,0.7652380494527506,0.7657123856224861,0.7661867217922216,0.7666610579619569,0.7671353941316924,0.7676097303014279,0.7680840664711632,0.7685584026408987,0.7690327388106342,0.7695070749803695,0.769981411150105,0.7704557473198405,0.7709300834895758,0.7714044196593113,0.7718787558290467,0.7723530919987821,0.7728274281685176,0.7733017643382529,0.7737761005079884,0.7742504366777239,0.7747247728474592,0.7751991090171947,0.7756734451869302,0.7761477813566655,0.776622117526401,0.7770964536961364,0.7775707898658718,0.7780451260356073,0.7785194622053427,0.7789937983750781,0.7794681345448136,0.779942470714549,0.7804168068842844,0.7808911430540199,0.7813654792237552,0.7818398153934907,0.7823141515632261,0.7827884877329615,0.783262823902697],\"y\":[0.01,0.01,0.01,0.01,0.03,0.03,0.03,0.03,0.03,0.03,0.03,0.04,0.04,0.04,0.04,0.04,0.04,0.05,0.05,0.05,0.05,0.06,0.06,0.06,0.06,0.06,0.06,0.07,0.09,0.09,0.09,0.11,0.11,0.11,0.11,0.11,0.11,0.11,0.12,0.12,0.12,0.14,0.14,0.14,0.14,0.17,0.17,0.17,0.21,0.21,0.21,0.23,0.23,0.23,0.23,0.29,0.29,0.29,0.32,0.32,0.32,0.32,0.37,0.37,0.37,0.42,0.42,0.42,0.42,0.44,0.44,0.44,0.54,0.54,0.54,0.6,0.61,0.61,0.61,0.72,0.72,0.72,0.77,0.77,0.77,0.77,0.86,0.86,0.86,0.91,0.91,0.91,0.91,0.98,0.98,0.98,0.99,0.99,0.99,1.0],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Empirical Distribution Function Plot\"},\"xaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Cumulative Probability\"},\"range\":[0,1]},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('141fe1a4-aeb1-493c-b033-db3a1287d04e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best of Optuna"
      ],
      "metadata": {
        "id": "RNxcJ3fe_nWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objecttive(trial):\n",
        "  classifier_name = trial.suggest_categorical('classifier', ['RandomForest', 'LogisticRegression', 'KNN'])\n",
        "\n",
        "  if classifier_name == 'RandomForest':\n",
        "    # Random Forrest Parameter\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
        "\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth)\n",
        "  elif classifier_name == 'LogisticRegression':\n",
        "    # Logistic Regression Parameter\n",
        "    penalty = trial.suggest_categorical('penalty', ['l2'])\n",
        "    C = trial.suggest_float('C', 0.001, 10)\n",
        "\n",
        "    model = LogisticRegression(\n",
        "        penalty=penalty,\n",
        "        C=C)\n",
        "  elif classifier_name == 'KNN':\n",
        "    # KNN Parameter\n",
        "    n_neighbors = trial.suggest_int('n_neighbors', 1, 10)\n",
        "    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
        "    p = trial.suggest_int('p', 1, 2)\n",
        "\n",
        "    model = KNeighborsClassifier(\n",
        "        n_neighbors=n_neighbors,\n",
        "        weights=weights,\n",
        "        p=p)\n",
        "\n",
        "  accuracy = cross_val_score(model, train_x, train_y, cv=10, scoring='accuracy').mean()\n",
        "\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "g7642A1j_dYg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create study object and Optimise it\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objecttive, n_trials=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HzrM2LcAiYa",
        "outputId": "158a4afa-c0eb-4e4c-97b2-9dad6e71d217"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-01-28 17:53:04,433] A new study created in memory with name: no-name-838de097-6d05-45c9-978b-0e90e9933252\n",
            "[I 2025-01-28 17:53:11,554] Trial 0 finished with value: 0.6938392384981491 and parameters: {'classifier': 'RandomForest', 'n_estimators': 340, 'max_depth': 1}. Best is trial 0 with value: 0.6938392384981491.\n",
            "[I 2025-01-28 17:53:13,489] Trial 1 finished with value: 0.7606028556319407 and parameters: {'classifier': 'RandomForest', 'n_estimators': 113, 'max_depth': 4}. Best is trial 1 with value: 0.7606028556319407.\n",
            "[I 2025-01-28 17:53:13,566] Trial 2 finished with value: 0.713379164463247 and parameters: {'classifier': 'KNN', 'n_neighbors': 6, 'weights': 'distance', 'p': 2}. Best is trial 1 with value: 0.7606028556319407.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:13,797] Trial 3 finished with value: 0.7702802749867794 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 3.3158561172748167}. Best is trial 3 with value: 0.7702802749867794.\n",
            "[I 2025-01-28 17:53:18,675] Trial 4 finished with value: 0.7606028556319407 and parameters: {'classifier': 'RandomForest', 'n_estimators': 235, 'max_depth': 5}. Best is trial 3 with value: 0.7702802749867794.\n",
            "[I 2025-01-28 17:53:18,832] Trial 5 finished with value: 0.7395822316234797 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 0.7702802749867794.\n",
            "[I 2025-01-28 17:53:18,924] Trial 6 finished with value: 0.7396086726599682 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'distance', 'p': 2}. Best is trial 3 with value: 0.7702802749867794.\n",
            "[I 2025-01-28 17:53:19,022] Trial 7 finished with value: 0.7396086726599682 and parameters: {'classifier': 'KNN', 'n_neighbors': 9, 'weights': 'distance', 'p': 2}. Best is trial 3 with value: 0.7702802749867794.\n",
            "[I 2025-01-28 17:53:19,116] Trial 8 finished with value: 0.7182178741406663 and parameters: {'classifier': 'KNN', 'n_neighbors': 3, 'weights': 'distance', 'p': 1}. Best is trial 3 with value: 0.7702802749867794.\n",
            "[I 2025-01-28 17:53:19,258] Trial 9 finished with value: 0.7314912744579587 and parameters: {'classifier': 'KNN', 'n_neighbors': 10, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:19,620] Trial 10 finished with value: 0.767028027498678 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 2.6416143264710414}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:20,022] Trial 11 finished with value: 0.7653886832363829 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 2.862129998842387}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:20,439] Trial 12 finished with value: 0.767028027498678 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 2.9426788526222674}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:20,747] Trial 13 finished with value: 0.765388683236383 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 6.809534838694853}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:20,992] Trial 14 finished with value: 0.7653622421998942 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 0.48822581281523636}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:21,265] Trial 15 finished with value: 0.7637757800105764 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 3.9785487504101367}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:21,491] Trial 16 finished with value: 0.7637493389740877 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 0.6284073456723211}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:21,734] Trial 17 finished with value: 0.7654151242728715 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 9.59701036645797}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:21,977] Trial 18 finished with value: 0.7686409307244844 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 6.007805927385823}. Best is trial 3 with value: 0.7702802749867794.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "[I 2025-01-28 17:53:22,254] Trial 19 finished with value: 0.7621099947117926 and parameters: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 6.384187122038884}. Best is trial 3 with value: 0.7702802749867794.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best parameter\n",
        "print(f\"Best trial: {study.best_trial.params}\")\n",
        "print(f\"Best accuracy: {study.best_trial.value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nmxeFTgAve3",
        "outputId": "c1bb270d-3b8d-4c20-e991-4eebb5ca6fc6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: {'classifier': 'LogisticRegression', 'penalty': 'l2', 'C': 3.3158561172748167}\n",
            "Best accuracy: 0.7702802749867794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualising Dataframe Formate"
      ],
      "metadata": {
        "id": "OpiYrjM3DTm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study.trials_dataframe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Sj7JdhqCUgZ",
        "outputId": "c822fdc3-a056-42ca-9e29-1b33bf655a07"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    number     value             datetime_start          datetime_complete  \\\n",
              "0        0  0.693839 2025-01-28 17:53:04.439921 2025-01-28 17:53:11.554231   \n",
              "1        1  0.760603 2025-01-28 17:53:11.557720 2025-01-28 17:53:13.489186   \n",
              "2        2  0.713379 2025-01-28 17:53:13.493290 2025-01-28 17:53:13.566559   \n",
              "3        3  0.770280 2025-01-28 17:53:13.568092 2025-01-28 17:53:13.797478   \n",
              "4        4  0.760603 2025-01-28 17:53:13.799033 2025-01-28 17:53:18.675363   \n",
              "5        5  0.739582 2025-01-28 17:53:18.681428 2025-01-28 17:53:18.831899   \n",
              "6        6  0.739609 2025-01-28 17:53:18.836669 2025-01-28 17:53:18.924582   \n",
              "7        7  0.739609 2025-01-28 17:53:18.928332 2025-01-28 17:53:19.022604   \n",
              "8        8  0.718218 2025-01-28 17:53:19.025203 2025-01-28 17:53:19.116429   \n",
              "9        9  0.731491 2025-01-28 17:53:19.121715 2025-01-28 17:53:19.258645   \n",
              "10      10  0.767028 2025-01-28 17:53:19.262872 2025-01-28 17:53:19.620321   \n",
              "11      11  0.765389 2025-01-28 17:53:19.624044 2025-01-28 17:53:20.022169   \n",
              "12      12  0.767028 2025-01-28 17:53:20.025987 2025-01-28 17:53:20.439301   \n",
              "13      13  0.765389 2025-01-28 17:53:20.444165 2025-01-28 17:53:20.746892   \n",
              "14      14  0.765362 2025-01-28 17:53:20.748314 2025-01-28 17:53:20.992062   \n",
              "15      15  0.763776 2025-01-28 17:53:20.993555 2025-01-28 17:53:21.265114   \n",
              "16      16  0.763749 2025-01-28 17:53:21.267476 2025-01-28 17:53:21.491030   \n",
              "17      17  0.765415 2025-01-28 17:53:21.492472 2025-01-28 17:53:21.734459   \n",
              "18      18  0.768641 2025-01-28 17:53:21.735920 2025-01-28 17:53:21.976842   \n",
              "19      19  0.762110 2025-01-28 17:53:21.978248 2025-01-28 17:53:22.254672   \n",
              "\n",
              "                 duration  params_C   params_classifier  params_max_depth  \\\n",
              "0  0 days 00:00:07.114310       NaN        RandomForest               1.0   \n",
              "1  0 days 00:00:01.931466       NaN        RandomForest               4.0   \n",
              "2  0 days 00:00:00.073269       NaN                 KNN               NaN   \n",
              "3  0 days 00:00:00.229386  3.315856  LogisticRegression               NaN   \n",
              "4  0 days 00:00:04.876330       NaN        RandomForest               5.0   \n",
              "5  0 days 00:00:00.150471       NaN                 KNN               NaN   \n",
              "6  0 days 00:00:00.087913       NaN                 KNN               NaN   \n",
              "7  0 days 00:00:00.094272       NaN                 KNN               NaN   \n",
              "8  0 days 00:00:00.091226       NaN                 KNN               NaN   \n",
              "9  0 days 00:00:00.136930       NaN                 KNN               NaN   \n",
              "10 0 days 00:00:00.357449  2.641614  LogisticRegression               NaN   \n",
              "11 0 days 00:00:00.398125  2.862130  LogisticRegression               NaN   \n",
              "12 0 days 00:00:00.413314  2.942679  LogisticRegression               NaN   \n",
              "13 0 days 00:00:00.302727  6.809535  LogisticRegression               NaN   \n",
              "14 0 days 00:00:00.243748  0.488226  LogisticRegression               NaN   \n",
              "15 0 days 00:00:00.271559  3.978549  LogisticRegression               NaN   \n",
              "16 0 days 00:00:00.223554  0.628407  LogisticRegression               NaN   \n",
              "17 0 days 00:00:00.241987  9.597010  LogisticRegression               NaN   \n",
              "18 0 days 00:00:00.240922  6.007806  LogisticRegression               NaN   \n",
              "19 0 days 00:00:00.276424  6.384187  LogisticRegression               NaN   \n",
              "\n",
              "    params_n_estimators  params_n_neighbors  params_p params_penalty  \\\n",
              "0                 340.0                 NaN       NaN            NaN   \n",
              "1                 113.0                 NaN       NaN            NaN   \n",
              "2                   NaN                 6.0       2.0            NaN   \n",
              "3                   NaN                 NaN       NaN             l2   \n",
              "4                 235.0                 NaN       NaN            NaN   \n",
              "5                   NaN                 9.0       2.0            NaN   \n",
              "6                   NaN                 9.0       2.0            NaN   \n",
              "7                   NaN                 9.0       2.0            NaN   \n",
              "8                   NaN                 3.0       1.0            NaN   \n",
              "9                   NaN                10.0       2.0            NaN   \n",
              "10                  NaN                 NaN       NaN             l2   \n",
              "11                  NaN                 NaN       NaN             l2   \n",
              "12                  NaN                 NaN       NaN             l2   \n",
              "13                  NaN                 NaN       NaN             l2   \n",
              "14                  NaN                 NaN       NaN             l2   \n",
              "15                  NaN                 NaN       NaN             l2   \n",
              "16                  NaN                 NaN       NaN             l2   \n",
              "17                  NaN                 NaN       NaN             l2   \n",
              "18                  NaN                 NaN       NaN             l2   \n",
              "19                  NaN                 NaN       NaN             l2   \n",
              "\n",
              "   params_weights     state  \n",
              "0             NaN  COMPLETE  \n",
              "1             NaN  COMPLETE  \n",
              "2        distance  COMPLETE  \n",
              "3             NaN  COMPLETE  \n",
              "4             NaN  COMPLETE  \n",
              "5         uniform  COMPLETE  \n",
              "6        distance  COMPLETE  \n",
              "7        distance  COMPLETE  \n",
              "8        distance  COMPLETE  \n",
              "9         uniform  COMPLETE  \n",
              "10            NaN  COMPLETE  \n",
              "11            NaN  COMPLETE  \n",
              "12            NaN  COMPLETE  \n",
              "13            NaN  COMPLETE  \n",
              "14            NaN  COMPLETE  \n",
              "15            NaN  COMPLETE  \n",
              "16            NaN  COMPLETE  \n",
              "17            NaN  COMPLETE  \n",
              "18            NaN  COMPLETE  \n",
              "19            NaN  COMPLETE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31a9270d-82d6-4a8c-b08c-fa41c65b5e86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_C</th>\n",
              "      <th>params_classifier</th>\n",
              "      <th>params_max_depth</th>\n",
              "      <th>params_n_estimators</th>\n",
              "      <th>params_n_neighbors</th>\n",
              "      <th>params_p</th>\n",
              "      <th>params_penalty</th>\n",
              "      <th>params_weights</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.693839</td>\n",
              "      <td>2025-01-28 17:53:04.439921</td>\n",
              "      <td>2025-01-28 17:53:11.554231</td>\n",
              "      <td>0 days 00:00:07.114310</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>1.0</td>\n",
              "      <td>340.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.760603</td>\n",
              "      <td>2025-01-28 17:53:11.557720</td>\n",
              "      <td>2025-01-28 17:53:13.489186</td>\n",
              "      <td>0 days 00:00:01.931466</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>4.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.713379</td>\n",
              "      <td>2025-01-28 17:53:13.493290</td>\n",
              "      <td>2025-01-28 17:53:13.566559</td>\n",
              "      <td>0 days 00:00:00.073269</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KNN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>distance</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.770280</td>\n",
              "      <td>2025-01-28 17:53:13.568092</td>\n",
              "      <td>2025-01-28 17:53:13.797478</td>\n",
              "      <td>0 days 00:00:00.229386</td>\n",
              "      <td>3.315856</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.760603</td>\n",
              "      <td>2025-01-28 17:53:13.799033</td>\n",
              "      <td>2025-01-28 17:53:18.675363</td>\n",
              "      <td>0 days 00:00:04.876330</td>\n",
              "      <td>NaN</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>5.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.739582</td>\n",
              "      <td>2025-01-28 17:53:18.681428</td>\n",
              "      <td>2025-01-28 17:53:18.831899</td>\n",
              "      <td>0 days 00:00:00.150471</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KNN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>uniform</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.739609</td>\n",
              "      <td>2025-01-28 17:53:18.836669</td>\n",
              "      <td>2025-01-28 17:53:18.924582</td>\n",
              "      <td>0 days 00:00:00.087913</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KNN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>distance</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.739609</td>\n",
              "      <td>2025-01-28 17:53:18.928332</td>\n",
              "      <td>2025-01-28 17:53:19.022604</td>\n",
              "      <td>0 days 00:00:00.094272</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KNN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>distance</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.718218</td>\n",
              "      <td>2025-01-28 17:53:19.025203</td>\n",
              "      <td>2025-01-28 17:53:19.116429</td>\n",
              "      <td>0 days 00:00:00.091226</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KNN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>distance</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.731491</td>\n",
              "      <td>2025-01-28 17:53:19.121715</td>\n",
              "      <td>2025-01-28 17:53:19.258645</td>\n",
              "      <td>0 days 00:00:00.136930</td>\n",
              "      <td>NaN</td>\n",
              "      <td>KNN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>uniform</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0.767028</td>\n",
              "      <td>2025-01-28 17:53:19.262872</td>\n",
              "      <td>2025-01-28 17:53:19.620321</td>\n",
              "      <td>0 days 00:00:00.357449</td>\n",
              "      <td>2.641614</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0.765389</td>\n",
              "      <td>2025-01-28 17:53:19.624044</td>\n",
              "      <td>2025-01-28 17:53:20.022169</td>\n",
              "      <td>0 days 00:00:00.398125</td>\n",
              "      <td>2.862130</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.767028</td>\n",
              "      <td>2025-01-28 17:53:20.025987</td>\n",
              "      <td>2025-01-28 17:53:20.439301</td>\n",
              "      <td>0 days 00:00:00.413314</td>\n",
              "      <td>2.942679</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.765389</td>\n",
              "      <td>2025-01-28 17:53:20.444165</td>\n",
              "      <td>2025-01-28 17:53:20.746892</td>\n",
              "      <td>0 days 00:00:00.302727</td>\n",
              "      <td>6.809535</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0.765362</td>\n",
              "      <td>2025-01-28 17:53:20.748314</td>\n",
              "      <td>2025-01-28 17:53:20.992062</td>\n",
              "      <td>0 days 00:00:00.243748</td>\n",
              "      <td>0.488226</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.763776</td>\n",
              "      <td>2025-01-28 17:53:20.993555</td>\n",
              "      <td>2025-01-28 17:53:21.265114</td>\n",
              "      <td>0 days 00:00:00.271559</td>\n",
              "      <td>3.978549</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.763749</td>\n",
              "      <td>2025-01-28 17:53:21.267476</td>\n",
              "      <td>2025-01-28 17:53:21.491030</td>\n",
              "      <td>0 days 00:00:00.223554</td>\n",
              "      <td>0.628407</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0.765415</td>\n",
              "      <td>2025-01-28 17:53:21.492472</td>\n",
              "      <td>2025-01-28 17:53:21.734459</td>\n",
              "      <td>0 days 00:00:00.241987</td>\n",
              "      <td>9.597010</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.768641</td>\n",
              "      <td>2025-01-28 17:53:21.735920</td>\n",
              "      <td>2025-01-28 17:53:21.976842</td>\n",
              "      <td>0 days 00:00:00.240922</td>\n",
              "      <td>6.007806</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>0.762110</td>\n",
              "      <td>2025-01-28 17:53:21.978248</td>\n",
              "      <td>2025-01-28 17:53:22.254672</td>\n",
              "      <td>0 days 00:00:00.276424</td>\n",
              "      <td>6.384187</td>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31a9270d-82d6-4a8c-b08c-fa41c65b5e86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31a9270d-82d6-4a8c-b08c-fa41c65b5e86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31a9270d-82d6-4a8c-b08c-fa41c65b5e86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-383186a4-366a-4627-a273-f9fa617e3b90\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-383186a4-366a-4627-a273-f9fa617e3b90')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-383186a4-366a-4627-a273-f9fa617e3b90 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"study\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          17,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02198834683324098,\n        \"min\": 0.6938392384981491,\n        \"max\": 0.7702802749867794,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.6938392384981491,\n          0.7606028556319407,\n          0.7396086726599682\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime_start\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-01-28 17:53:04.439921\",\n        \"max\": \"2025-01-28 17:53:21.978248\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"2025-01-28 17:53:04.439921\",\n          \"2025-01-28 17:53:21.492472\",\n          \"2025-01-28 17:53:20.993555\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime_complete\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-01-28 17:53:11.554231\",\n        \"max\": \"2025-01-28 17:53:22.254672\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"2025-01-28 17:53:11.554231\",\n          \"2025-01-28 17:53:21.734459\",\n          \"2025-01-28 17:53:21.265114\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"timedelta64[ns]\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"0 days 00:00:07.114310\",\n          \"0 days 00:00:00.241987\",\n          \"0 days 00:00:00.271559\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.776921615394022,\n        \"min\": 0.48822581281523636,\n        \"max\": 9.59701036645797,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.48822581281523636,\n          3.3158561172748167,\n          6.007805927385823\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_classifier\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"RandomForest\",\n          \"KNN\",\n          \"LogisticRegression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_max_depth\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.081665999466133,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          4.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_n_estimators\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 113.60604444013238,\n        \"min\": 113.0,\n        \"max\": 340.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          340.0,\n          113.0,\n          235.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_n_neighbors\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6583202716502514,\n        \"min\": 3.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          9.0,\n          10.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.408248290463863,\n        \"min\": 1.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_penalty\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"l2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_weights\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"uniform\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"COMPLETE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uto8p89DDeB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}